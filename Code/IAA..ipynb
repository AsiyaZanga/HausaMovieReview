{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpdpCghlmbtn",
        "outputId": "df4a9e87-26a7-4ab7-d8e8-985bb350aea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pairwise Cohen's kappa statistics:\n",
            "  Annotator 1 vs Annotator 2: 0.7975\n",
            "  Annotator 1 vs Annotator 3: 0.9071\n",
            "  Annotator 2 vs Annotator 3: 0.8903\n",
            "\n",
            "Fleiss' kappa across all annotators: 0.8650\n",
            "\n",
            "Annotator 1 distribution:\n",
            "  Negative: 1165 (23.30%)\n",
            "  Neutral: 996 (19.92%)\n",
            "  Positive: 2839 (56.78%)\n",
            "\n",
            "Annotator 2 distribution:\n",
            "  Negative: 1165 (23.30%)\n",
            "  Neutral: 995 (19.90%)\n",
            "  Positive: 2840 (56.80%)\n",
            "\n",
            "Annotator 3 distribution:\n",
            "  Negative: 1165 (23.30%)\n",
            "  Neutral: 995 (19.90%)\n",
            "  Positive: 2840 (56.80%)\n",
            "\n",
            "Majority vote distribution (across annotators):\n",
            "  Negative: 1165 (23.30%)\n",
            "  Neutral: 995 (19.90%)\n",
            "  Positive: 2840 (56.80%)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Annotation analysis for inter-annotator agreement and class distribution\n",
        "\n",
        "This script reads three Excel files containing annotations from three different\n",
        "annotators, normalises the class labels (to fix misspellings and case\n",
        "variations), computes inter‑annotator agreement (pairwise Cohen's kappa and\n",
        "overall Fleiss' kappa) and produces class distribution counts for each\n",
        "annotator and for the majority‑vote aggregate.\n",
        "\n",
        "To run the script, make sure `pandas`, `scikit‑learn` and `statsmodels` are\n",
        "installed in your Python environment. Execute with e.g.:\n",
        "\n",
        "    python annotation_analysis.py\n",
        "\n",
        "Adjust the `file_paths` list if the Excel files are named differently or\n",
        "located in another directory.\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from statsmodels.stats.inter_rater import fleiss_kappa\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def normalize_label(label: str) -> str:\n",
        "    \"\"\"Normalise raw annotation labels to one of ``Negative``, ``Neutral`` or ``Positive``.\n",
        "\n",
        "    The datasets sometimes contain misspellings such as ``Negetive`` or mixed\n",
        "    case (e.g. ``negetive``). This function strips whitespace, lowercases\n",
        "    the input and maps anything starting with ``neg`` to ``Negative``,\n",
        "    anything starting with ``pos`` to ``Positive``, and everything else to\n",
        "    ``Neutral``.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    label : str\n",
        "        The raw label from the dataset.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        The normalised label.\n",
        "    \"\"\"\n",
        "    label_lower = label.strip().lower()\n",
        "    if label_lower.startswith(\"neg\") or label_lower == \"negative\":\n",
        "        return \"Negative\"\n",
        "    elif label_lower.startswith(\"pos\"):\n",
        "        return \"Positive\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "\n",
        "def load_and_normalise(file_path: str) -> pd.Series:\n",
        "    \"\"\"Load an Excel file and return a pandas Series of normalised labels.\n",
        "\n",
        "    Only the ``label`` column is used. Each entry is converted to a\n",
        "    normalised category via :func:`normalize_label`.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    file_path : str\n",
        "        Path to the Excel file.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pandas.Series\n",
        "        Series of normalised labels.\n",
        "    \"\"\"\n",
        "    df = pd.read_excel(file_path)\n",
        "    return df[\"label\"].astype(str).apply(normalize_label)\n",
        "\n",
        "\n",
        "def compute_pairwise_kappas(norm_labels: list) -> dict:\n",
        "    \"\"\"Compute Cohen's kappa for every pair of annotators.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    norm_labels : list of pandas.Series\n",
        "        List where each element is a Series of normalised labels for one\n",
        "        annotator. All Series must be the same length and correspond to the\n",
        "        same items.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "        Dictionary keyed by a tuple of annotator indices (1‑based) with the\n",
        "        kappa statistic as value.\n",
        "    \"\"\"\n",
        "    kappas = {}\n",
        "    n_annotators = len(norm_labels)\n",
        "    for i in range(n_annotators):\n",
        "        for j in range(i + 1, n_annotators):\n",
        "            kappa = cohen_kappa_score(norm_labels[i], norm_labels[j])\n",
        "            kappas[(i + 1, j + 1)] = kappa\n",
        "    return kappas\n",
        "\n",
        "\n",
        "def compute_fleiss_kappa(norm_labels: list, categories: list) -> float:\n",
        "    \"\"\"Compute Fleiss' kappa across all annotators.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    norm_labels : list of pandas.Series\n",
        "        List of normalised labels for each annotator (length must equal the\n",
        "        number of annotators).\n",
        "    categories : list of str\n",
        "        The possible categories. This should contain exactly the distinct\n",
        "        normalised labels used in ``norm_labels``.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    float\n",
        "        Fleiss' kappa statistic.\n",
        "    \"\"\"\n",
        "    n_samples = len(norm_labels[0])\n",
        "    n_categories = len(categories)\n",
        "    # Build matrix: rows are items, columns are categories, values are counts of\n",
        "    # raters assigning that category to the item.\n",
        "    rating_matrix = np.zeros((n_samples, n_categories), dtype=int)\n",
        "    for i in range(n_samples):\n",
        "        votes = [annot[i] for annot in norm_labels]\n",
        "        for j, cat in enumerate(categories):\n",
        "            rating_matrix[i, j] = sum(1 for v in votes if v == cat)\n",
        "    return float(fleiss_kappa(rating_matrix))\n",
        "\n",
        "\n",
        "def compute_majority_distribution(norm_labels: list) -> Counter:\n",
        "    \"\"\"Compute the majority vote for each item and return distribution counts.\n",
        "\n",
        "    In case of ties (e.g. each annotator chooses a different label), no\n",
        "    majority category is assigned and the item is counted under ``No\n",
        "    Majority``.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    norm_labels : list of pandas.Series\n",
        "        List of normalised labels for each annotator.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    collections.Counter\n",
        "        Counts of majority categories across items.\n",
        "    \"\"\"\n",
        "    n_samples = len(norm_labels[0])\n",
        "    majority = []\n",
        "    for i in range(n_samples):\n",
        "        votes = [annot[i] for annot in norm_labels]\n",
        "        vote_counts = Counter(votes)\n",
        "        most_common = vote_counts.most_common(1)[0]\n",
        "        label, count = most_common\n",
        "        if count == 1:\n",
        "            majority.append(\"No Majority\")\n",
        "        else:\n",
        "            majority.append(label)\n",
        "    return Counter(majority)\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Paths to the annotator files\n",
        "    file_paths = [\n",
        "        \"/content/drive/MyDrive/dataset/Annotator 1.xlsx\",\n",
        "        \"/content/drive/MyDrive/dataset/Annotator 2.xlsx\",\n",
        "        \"/content/drive/MyDrive/dataset/Annotator 3.xlsx\",\n",
        "    ]\n",
        "\n",
        "    # Load and normalise labels\n",
        "    norm_labels = [load_and_normalise(fp) for fp in file_paths]\n",
        "\n",
        "    # Compute pairwise Cohen's kappa\n",
        "    pairwise = compute_pairwise_kappas(norm_labels)\n",
        "    print(\"Pairwise Cohen's kappa statistics:\")\n",
        "    for (i, j), kappa in pairwise.items():\n",
        "        print(f\"  Annotator {i} vs Annotator {j}: {kappa:.4f}\")\n",
        "\n",
        "    # Compute Fleiss' kappa across all annotators\n",
        "    categories = sorted(set(norm_labels[0]))  # Should be ['Negative','Neutral','Positive']\n",
        "    fkappa = compute_fleiss_kappa(norm_labels, categories)\n",
        "    print(f\"\\nFleiss' kappa across all annotators: {fkappa:.4f}\\n\")\n",
        "\n",
        "    # Show class distribution for each annotator with counts and percentages\n",
        "    total_items = len(norm_labels[0])\n",
        "    for idx, labels in enumerate(norm_labels, start=1):\n",
        "        counts = Counter(labels)\n",
        "        print(f\"Annotator {idx} distribution:\")\n",
        "        for cat in categories:\n",
        "            cnt = counts.get(cat, 0)\n",
        "            pct = (cnt / total_items) * 100\n",
        "            print(f\"  {cat}: {cnt} ({pct:.2f}%)\")\n",
        "        print()\n",
        "\n",
        "    # Majority vote distribution\n",
        "    majority_counts = compute_majority_distribution(norm_labels)\n",
        "    print(\"Majority vote distribution (across annotators):\")\n",
        "    for cat in categories + [\"No Majority\"]:\n",
        "        if cat in majority_counts:\n",
        "            cnt = majority_counts[cat]\n",
        "            pct = (cnt / total_items) * 100\n",
        "            print(f\"  {cat}: {cnt} ({pct:.2f}%)\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6D-F8qdFnTUV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}